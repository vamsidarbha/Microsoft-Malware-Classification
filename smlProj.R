#preprocessing
newdata = read.csv("data.csv",as.is =TRUE)
trainLabels = read.csv("trainLabels.csv", as.is =TRUE)

#combine data wiht trainLabels
newtrain = merge(newdata,trainLabels, by.x ="X01azqd4InC7m9JpocGv5", by.y ="Id")

#splitting the data
require(caTools)
set.seed=98
split=sample.split(newtrain, SplitRatio=0.8)

train = subset(newtrain, split==TRUE)
test = subset(newtrain, split==FALSE)


#Removing the non numeric columns
leftOut = setdiff(names(train), "X01azqd4InC7m9JpocGv5")
newTrain = newtrain[c(leftOut)]
trainFinal = train[c(leftOut)]
testFinal = test[c(leftOut)]

#Train nn
require(nnet)
modlelNN = multinom(Class~., data=trainFinal)
predNN = predict(modlelNN, newdata=testFinal)
table(testFinal$Class, predNN)

#75.9 accuracy

#Train LiblineaR
require(LiblineaR)
# Add dummy column
leftOuts = setdiff(names(trainFinal), c('Class','X1367070','X1320'))
trainForLinear = trainFinal[c(leftOuts)]
pred = trainFinal$Class
modelLinear = LiblineaR(data=trainForLinear,target = pred,type=0,cross=10)


#For test preprocess it
#remove filename
#adjust columns and set col names


testForLinear = testFinal[c(leftOuts)]
predLinear = predict(modelLinear,testForLinear,proba=TRUE)
table(testFinal$Class, predLinear$predictions)

b=table(predLinear$predictions)/nrow(testFinal)

#87.4 accuracy

#Baseline
acc=table(testFinal$Class)/nrow(testFinal)

# 1           2           3           4           5           6           7 
#0.138840070 0.225395431 0.277680141 0.042618629 0.003075571 0.064147627 0.033831283 
#8           9 
#0.124780316 0.089630931 


sum=0

for(i in 1:nrow(testFinal)){
  p=predLinear$probabilities[i,testFinal$Class[i]]
  p=max(min(p,1???10^-15),10^-15)
  sum =sum+ (p)  
}
sum/nrow(testFinal)

