#preprocessing
newdata = read.csv("data.csv",as.is =TRUE, header=FALSE)
trainLabels = read.csv("trainLabels.csv", as.is =TRUE)

#combine data wiht trainLabels
byteTrain= read.csv("featuresfromraw-free from missing.csv",as.is=TRUE)
byteTrain = byteTrain[c(setdiff(names(byteTrain),c("X","Class")))]
train = merge(byteTrain,newdata, by.y = "V42", by.x="Id")
newtrain = merge(train,trainLabels, by.x ="Id", by.y ="Id")

#Removing the non numeric columns
leftOut = setdiff(names(newtrain), "Id")
trainFinal = newtrain[c(leftOut)]


#Train LiblineaR
require(LiblineaR)
# Add dummy column
leftOuts = setdiff(names(trainFinal), c('Class','X1367070','X1320'))
trainForLinear = trainFinal[c(leftOuts)]
pred = trainFinal$Class
modelLinear = LiblineaR(data=trainForLinear,target = pred,type=0,cross=10)


#For test preprocess it
#remove filename
#adjust columns and set col names
test=read.csv("data3.csv",as.is=TRUE)
byteTest =  read.csv("completetestFeatures.csv",as.is=TRUE)
byteTest = byteTest[c(setdiff(names(byteTest),"X"))]
newtest = merge(byteTest,test, by.y = "Ig2DB5tSiEy1cJvV0zdw", by.x="Id")
colnames(newtest)=setdiff(names(newtrain),"Class")
testFinal = newtest
leftOuts = setdiff(names(testFinal), c('X1367070','X1320','Id'))
testForLinear = testFinal[c(leftOuts)]
predLinear = predict(modelLinear,testForLinear,proba=TRUE)
table(testFinal$Class, predLinear$predictions)

b=table(predLinear$predictions)/nrow(testFinal)

#87.4 accuracy

#Baseline
acc=table(testFinal$Class)/nrow(testFinal)

# 1           2           3           4           5           6           7 
#0.138840070 0.225395431 0.277680141 0.042618629 0.003075571 0.064147627 0.033831283 
#8           9 
#0.124780316 0.089630931 


sum=0

for(i in 1:nrow(testFinal)){
  p=predLinear$probabilities[i,testFinal$Class[i]]
  p=max(min(p,1???10^-15),10^-15)
  sum =sum+ (p)  
}
sum/nrow(testFinal)
